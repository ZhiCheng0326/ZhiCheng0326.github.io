---
title: 'NEFTune: Noisy Embedding Instruction Fine Tuning'
date: 2023-11-21
permalink: /posts/2023/11/2023-11-21-neftune/
tags:
  - LLM
  - LLM fine-tuning
---

This paper proposes NEFTune, a simple trick by **adding noise to embedding vectors** during training which improve the outcome of instruction fine-tuning by large margin. If you are using SFT trainier by huggingface, you can use this trick by simply adding one line of code!

<div role="note" style="display: flex;"><div style="display: flex; width: 100%; border-radius: 4px; background: rgb(241, 241, 239); padding: 16px 16px 16px 12px;"><div><div role="button" tabindex="0" class="notion-record-icon notranslate" aria-label="ðŸ’¡ Change callout icon" style="user-select: none; transition: background 20ms ease-in 0s; cursor: pointer; display: flex; align-items: center; justify-content: center; height: 24px; width: 24px; border-radius: 0.25em; flex-shrink: 0;"><div style="display: flex; align-items: center; justify-content: center; height: 24px; width: 24px;"><div style="height: 21.6px; width: 21.6px; font-size: 21.6px; line-height: 1; margin-left: 0px; color: black;"><span role="img" aria-label="ðŸ’¡" style="font-family: &quot;Apple Color Emoji&quot;, &quot;Segoe UI Emoji&quot;, NotoColorEmoji, &quot;Noto Color Emoji&quot;, &quot;Segoe UI Symbol&quot;, &quot;Android Emoji&quot;, EmojiSymbols; line-height: 1em; white-space: nowrap;">ðŸ’¡</span></div></div></div></div><div style="display: flex; flex-direction: column; min-width: 0px; margin-left: 8px; width: 100%;"><details><summary>Table of Contents</summary><div data-block-id="17e9fba4-714e-4264-a6e6-7c0e624ddb88" class="notion-selectable notion-table_of_contents-block" style="width: 100%; max-width: 100%; margin-top: 4px; margin-bottom: 0px;"><div contenteditable="false" data-content-editable-void="true" style="position: relative;"><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#abstract" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Abstract</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#methodology" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Methodology</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#results" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Results</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#conversational-ability" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 24px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Conversational ability</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#further-improvement-on-chat-models" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 24px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Further improvement on chat models</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#does-neftune-sacrifices-performance-on-other-tasks-to-improve-conversational-ability" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 24px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Does NEFTune sacrifices performance on other tasks to improve conversational ability?</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#reference" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Reference</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#link" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Link</div></div></a></div><div style="color: rgb(120, 119, 116); fill: rgb(120, 119, 116);"><a href="#appendix" rel="noopener noreferrer" style="display: block; color: inherit; text-decoration: none; user-select: none; transition: background 20ms ease-in 0s; cursor: pointer;"><div style="padding: 6px 2px; font-size: 14px; line-height: 1.3; display: flex; align-items: center; margin-left: 0px;"><div class="notranslate" style="white-space: nowrap; overflow: hidden; text-overflow: ellipsis; background-image: linear-gradient(to right, rgba(55, 53, 47, 0.16) 0%, rgba(55, 53, 47, 0.16) 100%); background-repeat: repeat-x; background-position: 0px 100%; background-size: 100% 1px;">Appendix</div></div></a></div></div></div></details></div></div></div>

<br />

# Abstract

- The author proposes NEFTune, a simple trick by **adding noise to embedding vectors** during training which improve the outcome of instruction fine-tuning by large margin
- This performance gain is as shown below:

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled.png)

# Methodology

- During fine-tuning, pairs of instruction and responses are sampled, in the form of text
- The text are then tokenized, then turned into embedding vectors.
- These embeddings are then added with random noise sampled from uniform distribution
- The noise are then scaled with $\frac{\alpha}{\sqrt {Ld}}$ , where  $\alpha$  is a tunable parameter, $L$ is the sequence length, $d$ is the embedding dimension
- Details:

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled%201.png)

# Results

- Most of the experiments are conducted using 7B parameters of LLMs, including LLaMa-1, LLaMa-2 and OPT-6.7B

## Conversational ability

- NEFTune improves **conversational** and **answer** **quality**, as measured via AlpacaEval

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled%202.png)

---

## Further improvement on chat models

- NEFTune can **further improve chat models**.
    - LLaMA-2-Chat (7B) is a extensively tuned model, with multiple rounds of RLHF.
    - Further tuning LLaMA-2 Chat (7B) on Evol-Instruct gives another 3% boosts
    - Furthermore, with NEFTune, we
    see a sizable, additional performance increase of 10%

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled%203.png)

- NEFTune **works with QLORA**

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled%204.png)

---

## Does NEFTune sacrifices performance on other tasks to improve conversational ability?

- Figure below shows that NEFTune **preserves model capabilities** on other tasks

![Untitled](/images/NEFTune%20Noisy%20Embedding%20Instruction%20Fine%20Tuning%200a80a01961814d21b35dfcc6c4b2783d/Untitled%205.png)

# Reference

1. Jain et al. â€œ[NEFTune: Noisy Embedding Instruction Fine Tuning](https://arxiv.org/abs/2310.05914), arXiv preprint arXiv:2310.05914 (2023)

# Link

1. [Github](https://github.com/neelsjain/NEFTune)
2. [Hugging Face documentation](https://huggingface.co/docs/trl/main/en/sft_trainer#enhance-models-performances-using-neftune)

# Appendix

To use it with SFT Trainer by huggingface

```python
from datasets import load_dataset
from trl import SFTTrainer

dataset = load_dataset("imdb", split="train")

trainer = SFTTrainer(
    "facebook/opt-350m",
    train_dataset=dataset,
    dataset_text_field="text",
    max_seq_length=512,
    neftune_noise_alpha=5,
)
trainer.train()
```

More details from [link](https://huggingface.co/docs/trl/main/en/sft_trainer#enhance-models-performances-using-neftune).

Detail implementation by [huggingface SFT trainer](https://github.com/huggingface/trl/blob/8e9cae8072714cea06bb39e57c692df86b6e2153/trl/trainer/utils.py#L742):

```python
def neftune_post_forward_hook(module, input, output):
    """
    Implements the NEFTune forward pass for the model using forward hooks. Note this works only for
    torch.nn.Embedding layers. This method is slightly adapted from the original source code
    that can be found here: https://github.com/neelsjain/NEFTune

    Simply add it to your model as follows:
    ```python
    model = ...
    model.embed_tokens.neftune_noise_alpha = 0.1
    model.embed_tokens.register_forward_hook(neftune_post_forward_hook)
    ```

    Args:
        module (`torch.nn.Module`):
            The embedding module where the hook is attached. Note that you need to set
            `module.neftune_noise_alpha` to the desired noise alpha value.
        input (`torch.Tensor`):
            The input tensor to the model.
        output (`torch.Tensor`):
            The output tensor of the model (i.e. the embeddings).
    """
    if module.training:
        dims = torch.tensor(output.size(1) * output.size(2))
        mag_norm = module.neftune_noise_alpha / torch.sqrt(dims)
        output = output + torch.zeros_like(output).uniform_(-mag_norm, mag_norm)
    return output
```